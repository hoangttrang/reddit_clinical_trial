{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis and Personalized Messaging \n",
    "## Project Overview: \n",
    "This project demonstrates the application of ethical web scraping, sentiment analysis, and AI-powered personalized messaging to identify potential participants for clinical trials. By analyzing posts and comments from Reddit, the project gauges user sentiments and interest levels toward clinical trials. Using these insights, the project generates customized outreach messages to engage users, leveraging the OpenAI API for dynamic message creation. The goal is to provide a scalable and ethical framework for clinical trial recruitment.\n",
    "## Notebook Overview: \n",
    "This notebook provides a comprehensive analysis of Reddit data to identify users who are interested in participating in clinical trials. It covers the following:\n",
    "\n",
    "1. Reddit Post Filtering: Identifies posts relevant to clinical trials based on a similarity score derived from cosine similarity with a predefined query. The score is calculated from `reddit_scrapping.py`. Posts focused on career discussions or unrelated topics are penalized.\n",
    "\n",
    "2. EDA: \n",
    "- Sentiment Analysis: Analyzes the sentiment (positive, neutral, negative) of posts and comments, identifying trends, topics, and linguistic patterns associated with each sentiment category.\n",
    "- Topic Modeling: Uses LDA to identify themes within posts and comments, distinguishing between sentiment-driven and general topics.\n",
    "Keyword Analysis with TF-IDF: Extracts significant words and phrases for each sentiment category to uncover linguistic patterns.\n",
    "- Interest Scoring: Develops a scoring system to rank users' interest levels in clinical trials based on their activity, sentiment, and intent.\n",
    "\n",
    "3. Personalized Messaging: Demonstrates how to generate tailored messages for users with high interest, using aggregated user content and extracted demographic data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Reddit Post that is Clinical Trials related \n",
    "\n",
    "The focus of this project is on posts from individuals who are interested in joining clinical trials or have prior experience participating in them. The aim is not to include posts that simply share news about clinical trials. For instance, a post in `r/science` discussing an article like \"Lab-grown retinal eye cells make successful connections, opening the door for clinical trials to treat blindness\" mentions clinical trials but does not involve individuals' personal experiences or intentions to join.\n",
    "\n",
    "\n",
    "I have chosen to scrape data exclusively from `r/clinicalresearch` and `r/clinicaltrials` (refered to `reddit_scrapping.py`). While it is possible that discussions about joining clinical trials might occur in disease-specific subreddits, individuals seeking urgent advice or sharing their experiences often cross-post to broader communities like these. Additionally, due to time constraints, scraping all disease-specific subreddits is not feasible.\n",
    "\n",
    "\n",
    "After fully scrape all the subreddit data from the about subreddit with `reddit_scrapping.py`; I also assign each post with a score that determines how relevant each post is since I am only interested in finding posts that talks about user wants to and have some questions about participating in a clinical trials or someone who already had experience in clinical trials \n",
    "\n",
    "This score is critical as it allows us to filter out posts that are not relevant with our project goal. The similarity score is calculated based on comparing cosine similarity between the `defined_query` and the combination of post's title and its body text and penalized and rewarded score based on keywords. I want to penalize on post that talks about career development and reward post that talks about clinical trial experience. \n",
    "The `defined_query` might need some more fine-tuning if later on the project.s\n",
    "\n",
    "```python\n",
    "defined_query = \"\"\"\n",
    "    I am looking for personal experiences in clinical trials or interest in joining one.\n",
    "    I am interested in learning more about the process of clinical trials and how they work, how to find and participate in clinical trials.\n",
    "    medicine, research, study, trials, drug, treatment, experimental, patient, clinical, health, participation, patient recruitment\n",
    "    Looking for patient recruitment\n",
    "    \"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from openai import OpenAI\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "from datetime import datetime\n",
    "import os \n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_wd = os.getcwd()\n",
    "# Load the JSON file\n",
    "file_path = f\"{current_wd}/data/post_data.json\"  # Replace with the path to your JSON file\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Convert the JSON dictionary to a DataFrame\n",
    "df = pd.DataFrame.from_dict(data, orient=\"index\")\n",
    "\n",
    "# remane column selftext to body_text\n",
    "df = df.rename(columns={\"selftext\": \"body_text\", \"weighted_similarity\":\"weighted_sim_score\"})\n",
    "\n",
    "df = df.sort_values(by='weighted_sim_score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the similarity score, if a post matches with what the interest topics which are about clinical trial experience and interest in participating in on, then the value would be larger than 0 and larger than 0.6. With this 0.6 threshold, I can then narrow to posts that match with my objective for sentiment analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>body_text</th>\n",
       "      <th>author</th>\n",
       "      <th>weighted_sim_score</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>created_date</th>\n",
       "      <th>score</th>\n",
       "      <th>url</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>d61idj</th>\n",
       "      <td>Types and phases of clinical trials</td>\n",
       "      <td>There are different types of clinical trials i...</td>\n",
       "      <td>gafaind</td>\n",
       "      <td>4.895395</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.568829e+09</td>\n",
       "      <td>2019-09-18</td>\n",
       "      <td>7</td>\n",
       "      <td>https://www.reddit.com/r/clinicaltrials/commen...</td>\n",
       "      <td>1</td>\n",
       "      <td>clinicaltrials</td>\n",
       "      <td>[{'author': 'DeanOnDelivery', 'body': 'What an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dd9irp</th>\n",
       "      <td>About Different Clinical Trials</td>\n",
       "      <td>Once on the market, the drug remains closely ...</td>\n",
       "      <td>canadianblog</td>\n",
       "      <td>3.559457</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.570206e+09</td>\n",
       "      <td>2019-10-04</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.reddit.com/r/clinicaltrials/commen...</td>\n",
       "      <td>0</td>\n",
       "      <td>clinicaltrials</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1gb033f</th>\n",
       "      <td>Trying to get a clinical trial started as a pr...</td>\n",
       "      <td>Hey, guys! I need some help, if possible. I ma...</td>\n",
       "      <td>empty-health-bar</td>\n",
       "      <td>3.040946</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.729768e+09</td>\n",
       "      <td>2024-10-24</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.reddit.com/r/clinicalresearch/comm...</td>\n",
       "      <td>71</td>\n",
       "      <td>clinicalresearch</td>\n",
       "      <td>[{'author': 'vathena', 'body': 'You should get...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ol3ysd</th>\n",
       "      <td>158 Recently Updated Clinical Trials - activel...</td>\n",
       "      <td>#158 Clinical Trials updated on 2021-07-14\\n\\n...</td>\n",
       "      <td>ClinicalTrialsBot</td>\n",
       "      <td>1.832374</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1.626390e+09</td>\n",
       "      <td>2021-07-15</td>\n",
       "      <td>4</td>\n",
       "      <td>https://www.reddit.com/r/clinicaltrials/commen...</td>\n",
       "      <td>0</td>\n",
       "      <td>clinicaltrials</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>olfc72</th>\n",
       "      <td>122 Recently Updated Clinical Trials - activel...</td>\n",
       "      <td>#122 Clinical Trials updated on 2021-07-15\\n\\n...</td>\n",
       "      <td>ClinicalTrialsBot</td>\n",
       "      <td>1.748216</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.626436e+09</td>\n",
       "      <td>2021-07-16</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.reddit.com/r/clinicaltrials/commen...</td>\n",
       "      <td>0</td>\n",
       "      <td>clinicaltrials</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     title  \\\n",
       "d61idj                 Types and phases of clinical trials   \n",
       "dd9irp                     About Different Clinical Trials   \n",
       "1gb033f  Trying to get a clinical trial started as a pr...   \n",
       "ol3ysd   158 Recently Updated Clinical Trials - activel...   \n",
       "olfc72   122 Recently Updated Clinical Trials - activel...   \n",
       "\n",
       "                                                 body_text             author  \\\n",
       "d61idj   There are different types of clinical trials i...            gafaind   \n",
       "dd9irp    Once on the market, the drug remains closely ...       canadianblog   \n",
       "1gb033f  Hey, guys! I need some help, if possible. I ma...   empty-health-bar   \n",
       "ol3ysd   #158 Clinical Trials updated on 2021-07-14\\n\\n...  ClinicalTrialsBot   \n",
       "olfc72   #122 Clinical Trials updated on 2021-07-15\\n\\n...  ClinicalTrialsBot   \n",
       "\n",
       "         weighted_sim_score  upvote_ratio   created_utc created_date  score  \\\n",
       "d61idj             4.895395          1.00  1.568829e+09   2019-09-18      7   \n",
       "dd9irp             3.559457          1.00  1.570206e+09   2019-10-04      1   \n",
       "1gb033f            3.040946          0.43  1.729768e+09   2024-10-24      0   \n",
       "ol3ysd             1.832374          0.84  1.626390e+09   2021-07-15      4   \n",
       "olfc72             1.748216          1.00  1.626436e+09   2021-07-16      1   \n",
       "\n",
       "                                                       url  num_comments  \\\n",
       "d61idj   https://www.reddit.com/r/clinicaltrials/commen...             1   \n",
       "dd9irp   https://www.reddit.com/r/clinicaltrials/commen...             0   \n",
       "1gb033f  https://www.reddit.com/r/clinicalresearch/comm...            71   \n",
       "ol3ysd   https://www.reddit.com/r/clinicaltrials/commen...             0   \n",
       "olfc72   https://www.reddit.com/r/clinicaltrials/commen...             0   \n",
       "\n",
       "                subreddit                                           comments  \n",
       "d61idj     clinicaltrials  [{'author': 'DeanOnDelivery', 'body': 'What an...  \n",
       "dd9irp     clinicaltrials                                                 []  \n",
       "1gb033f  clinicalresearch  [{'author': 'vathena', 'body': 'You should get...  \n",
       "ol3ysd     clinicaltrials                                                 []  \n",
       "olfc72     clinicaltrials                                                 []  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter rows with weighted_sim_score > 0.6\n",
    "processed_df = df.copy()\n",
    "processed_df = processed_df[processed_df['weighted_sim_score'] >= 0.6]\n",
    "print(processed_df.shape)\n",
    "processed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'body_text', 'author', 'weighted_sim_score', 'upvote_ratio',\n",
       "       'created_utc', 'created_date', 'score', 'url', 'num_comments',\n",
       "       'subreddit', 'comments'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA: Sentiment Analysis\n",
    "Some of the sentiment analysis questions that I am interested in answering given the above data \n",
    "\n",
    "1. What are the dominant sentiments (positive, neutral, negative) expressed in posts/ comments about clinical trials?\n",
    "2. Are there specific topics within the posts (e.g., patient experience, risks, benefits) that show stronger positive or negative sentiment?\n",
    "3. What keywords or phrases are strongly associated with neutral, positive or negative sentiment in posts and comments?\n",
    "4. How can we identify users who are most interested in clinical trials based on their activity, sentiment, and intent?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comments dataframe shape:  (11570, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>post_title</th>\n",
       "      <th>comment_author</th>\n",
       "      <th>comment_body</th>\n",
       "      <th>comment_score</th>\n",
       "      <th>comment_created_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d61idj</td>\n",
       "      <td>Types and phases of clinical trials</td>\n",
       "      <td>DeanOnDelivery</td>\n",
       "      <td>What an excellent post. About the only thing I...</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-12-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1gb033f</td>\n",
       "      <td>Trying to get a clinical trial started as a pr...</td>\n",
       "      <td>vathena</td>\n",
       "      <td>You should get off reddit and go connect with ...</td>\n",
       "      <td>107</td>\n",
       "      <td>2024-10-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1gb033f</td>\n",
       "      <td>Trying to get a clinical trial started as a pr...</td>\n",
       "      <td>NewBenefit6035</td>\n",
       "      <td>How many participants, funding,  starting larg...</td>\n",
       "      <td>24</td>\n",
       "      <td>2024-10-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1gb033f</td>\n",
       "      <td>Trying to get a clinical trial started as a pr...</td>\n",
       "      <td>FuriousKittens</td>\n",
       "      <td>You might have some success petitioning the sp...</td>\n",
       "      <td>19</td>\n",
       "      <td>2024-10-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1gb033f</td>\n",
       "      <td>Trying to get a clinical trial started as a pr...</td>\n",
       "      <td>Gazorninplat6</td>\n",
       "      <td>It's great when private citizens want to get i...</td>\n",
       "      <td>6</td>\n",
       "      <td>2024-10-24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id                                         post_title  comment_author  \\\n",
       "0   d61idj                Types and phases of clinical trials  DeanOnDelivery   \n",
       "1  1gb033f  Trying to get a clinical trial started as a pr...         vathena   \n",
       "2  1gb033f  Trying to get a clinical trial started as a pr...  NewBenefit6035   \n",
       "3  1gb033f  Trying to get a clinical trial started as a pr...  FuriousKittens   \n",
       "4  1gb033f  Trying to get a clinical trial started as a pr...   Gazorninplat6   \n",
       "\n",
       "                                        comment_body  comment_score  \\\n",
       "0  What an excellent post. About the only thing I...              1   \n",
       "1  You should get off reddit and go connect with ...            107   \n",
       "2  How many participants, funding,  starting larg...             24   \n",
       "3  You might have some success petitioning the sp...             19   \n",
       "4  It's great when private citizens want to get i...              6   \n",
       "\n",
       "  comment_created_date  \n",
       "0           2019-12-23  \n",
       "1           2024-10-24  \n",
       "2           2024-10-24  \n",
       "3           2024-10-24  \n",
       "4           2024-10-24  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a comments only data \n",
    "# Assuming `df` is the original DataFrame\n",
    "comments_data = []\n",
    "\n",
    "# Iterate through each post and its comments\n",
    "for post_id, row in df.iterrows():\n",
    "    post_title = row['title']  # Get the post title\n",
    "    post_author = row['author']  # Get the post author\n",
    "    for comment in row['comments']:\n",
    "        # Append each comment's data to the list\n",
    "        comments_data.append({\n",
    "            'post_id': post_id,\n",
    "            'post_title': post_title,\n",
    "            'comment_author': comment['author'],\n",
    "            'comment_body': comment['body'],\n",
    "            'comment_score': comment['score'],\n",
    "            'comment_created_date': datetime.fromtimestamp(comment['created_utc']).strftime('%Y-%m-%d'),\n",
    "        })\n",
    "\n",
    "# Create a new DataFrame from the flattened comments data\n",
    "comments_df = pd.DataFrame(comments_data)\n",
    "print(\"Comments dataframe shape: \", comments_df.shape)\n",
    "comments_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis with Pre-trained Model for Posts and Comments data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to C:\\Users\\tata\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "# per post \n",
    "from transformers import pipeline\n",
    "from huggingface_hub import login \n",
    "hugging_token= os.getenv(\"HUGGINGFACE_API_KEY\")\n",
    "print(hugging_token)\n",
    "login(token=hugging_token)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "I use the **\"cardiffnlp/twitter-roberta-base-sentiment-latest\"** model, a pre-trained sentiment analysis model based on the Roberta architecture. Although trained on tweet data, its similarity to Reddit language makes it suitable for this task.\n",
    "\n",
    "To handle longer Reddit posts, I combine the title and body text, split the text into smaller chunks, and analyze each chunk. The dominant sentiment across all chunks determines the overall sentiment of the post. This approach adapts the model to longer content effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\blurry_clear_imagedetection\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_path = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\", model=model_path, tokenizer= model_path)\n",
    "\n",
    "def analyze_sentiment(pipeline, text):\n",
    "    max_length = 512\n",
    "    # Split text into smaller chunks to avoid token limit\n",
    "    chunks = [text[i:i+max_length] for i in range(0, len(text), max_length)]\n",
    "    # If only one chunk, return the pipeline result directly\n",
    "    if len(chunks) == 1:\n",
    "        result = pipeline(chunks[0])[0]\n",
    "        return result['label'].lower(), result['score']\n",
    "\n",
    "    # If multiple chunks, analyze sentiment for each\n",
    "    sentiments = [pipeline(chunk)[0] for chunk in chunks]\n",
    "\n",
    "    # Determine the predominant label\n",
    "    label_counts = {}\n",
    "    for sentiment in sentiments:\n",
    "        label = sentiment['label'].lower()\n",
    "        label_counts[label] = label_counts.get(label, 0) + 1\n",
    "    predominant_label = max(label_counts, key=label_counts.get)\n",
    "    # Calculate the average score for the predominant label\n",
    "    avg_score = sum(s['score'] for s in sentiments if s['label'].lower() == predominant_label) / label_counts[predominant_label]\n",
    "\n",
    "    return  predominant_label,  avg_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df[['sentiment_label', 'sentiment_score']] = processed_df.apply(\n",
    "    lambda row: pd.Series(analyze_sentiment(sentiment_pipeline, row['title'] + \" \" + row['body_text'])),\n",
    "    axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment_label\n",
       "neutral     75\n",
       "positive    13\n",
       "negative    12\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df['sentiment_label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a good chunk of the post, the sentiment is relatively neutral. It kinda make sense as the typically people make posts to share that they are looking for information or even post about clinical trials "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11570, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>post_title</th>\n",
       "      <th>comment_author</th>\n",
       "      <th>comment_body</th>\n",
       "      <th>comment_score</th>\n",
       "      <th>comment_created_date</th>\n",
       "      <th>sentiment_label</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d61idj</td>\n",
       "      <td>Types and phases of clinical trials</td>\n",
       "      <td>DeanOnDelivery</td>\n",
       "      <td>What an excellent post. About the only thing I...</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-12-23</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.870846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1gb033f</td>\n",
       "      <td>Trying to get a clinical trial started as a pr...</td>\n",
       "      <td>vathena</td>\n",
       "      <td>You should get off reddit and go connect with ...</td>\n",
       "      <td>107</td>\n",
       "      <td>2024-10-24</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.778827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1gb033f</td>\n",
       "      <td>Trying to get a clinical trial started as a pr...</td>\n",
       "      <td>NewBenefit6035</td>\n",
       "      <td>How many participants, funding,  starting larg...</td>\n",
       "      <td>24</td>\n",
       "      <td>2024-10-24</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.687680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1gb033f</td>\n",
       "      <td>Trying to get a clinical trial started as a pr...</td>\n",
       "      <td>FuriousKittens</td>\n",
       "      <td>You might have some success petitioning the sp...</td>\n",
       "      <td>19</td>\n",
       "      <td>2024-10-24</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.730971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1gb033f</td>\n",
       "      <td>Trying to get a clinical trial started as a pr...</td>\n",
       "      <td>Gazorninplat6</td>\n",
       "      <td>It's great when private citizens want to get i...</td>\n",
       "      <td>6</td>\n",
       "      <td>2024-10-24</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.560070</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id                                         post_title  comment_author  \\\n",
       "0   d61idj                Types and phases of clinical trials  DeanOnDelivery   \n",
       "1  1gb033f  Trying to get a clinical trial started as a pr...         vathena   \n",
       "2  1gb033f  Trying to get a clinical trial started as a pr...  NewBenefit6035   \n",
       "3  1gb033f  Trying to get a clinical trial started as a pr...  FuriousKittens   \n",
       "4  1gb033f  Trying to get a clinical trial started as a pr...   Gazorninplat6   \n",
       "\n",
       "                                        comment_body  comment_score  \\\n",
       "0  What an excellent post. About the only thing I...              1   \n",
       "1  You should get off reddit and go connect with ...            107   \n",
       "2  How many participants, funding,  starting larg...             24   \n",
       "3  You might have some success petitioning the sp...             19   \n",
       "4  It's great when private citizens want to get i...              6   \n",
       "\n",
       "  comment_created_date sentiment_label  sentiment_score  \n",
       "0           2019-12-23        positive         0.870846  \n",
       "1           2024-10-24        negative         0.778827  \n",
       "2           2024-10-24         neutral         0.687680  \n",
       "3           2024-10-24         neutral         0.730971  \n",
       "4           2024-10-24         neutral         0.560070  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sentiment analysis for comments\n",
    "comments_df[['sentiment_label', 'sentiment_score']] = comments_df.apply(\n",
    "    lambda row: pd.Series(analyze_sentiment(sentiment_pipeline, row['comment_body'])),\n",
    "    axis=1)\n",
    "print(comments_df.shape)\n",
    "comments_df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment_label\n",
       "neutral     5775\n",
       "negative    3359\n",
       "positive    2436\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find how many comments are positive, negative and neutral\n",
    "comments_df['sentiment_label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations** \n",
    "- More than 70% of posts lean towards neutral sentiment, possibly reflecting a more informative or less subjective tone.\n",
    "- Comments provide a slightly richer sentiment distribution. Eventhough the dominant sentiment is still neutral, n~egative comments (~29%) outnumber positive ones (21%), suggesting that users may express concerns, criticisms, or negative experiences more frequently in the comment sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Identify for Posts and Comment by sentiment\n",
    "This section examines whether specific topics (e.g., patient experiences, risks, benefits) are associated with positive, negative, or neutral sentiment in posts and comments.\n",
    "\n",
    "Methodology\n",
    "- General Topic Modeling:\n",
    "    -   Apply LDA with 5 topics to all posts using CountVectorizer to preprocess the text.\n",
    "- Sentiment-Specific Modeling:\n",
    "    - Perform LDA separately on positive, negative, and neutral posts and comments to identify sentiment-driven theme\n",
    "    \n",
    "The top 10 keywords for each topic are extracted, highlighting how themes vary across sentiments. From these keywords, we can then extract/reveals pattern that related to clinical trials \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: ['time', 'like', 'treatment', 'patient', 'patients', 'research', 'trials', 'study', 'trial', 'clinical']\n",
      "Topic 1: ['nyulangone', 'traumatic', 'symptoms', 'ptsd', 'participants', 'com', 'study', 'survey', 'https', 'org']\n",
      "Topic 2: ['niaid', 'university', 'study', 'bethesda', '18', 'md', 'usa', 'clinicaltrials', 'gov', 'https']\n",
      "Topic 3: ['countries', '60', 'paid', 'safety', 'age', 'factors', 'cov', 'brain', 'early', 'state']\n",
      "Topic 4: ['treatment', 'cost', 'thanks', 'hospital', 'hi', 'interested', 'non', 'different', 'clinical', 'trials']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# General Topic Modeling without sentiment\n",
    "vectorizer = CountVectorizer(max_df=0.9, min_df=10, stop_words='english')\n",
    "dtm = vectorizer.fit_transform(processed_df['body_text'])\n",
    "\n",
    "# Fit LDA model\n",
    "lda = LatentDirichletAllocation(n_components=5, random_state=42)  # 5 topics\n",
    "lda.fit(dtm)\n",
    "\n",
    "# Extract topics\n",
    "for idx, topic in enumerate(lda.components_):\n",
    "    print(f\"Topic {idx}: {[vectorizer.get_feature_names_out()[i] for i in topic.argsort()[-10:]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to perform LDA and print topics for a given sentiment\n",
    "def analyze_topics_for_sentiment(data, sentiment_label, n_topics=5, max_features=10):\n",
    "    print(f\"\\nAnalyzing topics for sentiment: {sentiment_label}\")\n",
    "    \n",
    "    # Filter data for the given sentiment\n",
    "    sentiment_data = data[data['sentiment_label'] == sentiment_label]['combined_text']\n",
    "    \n",
    "    if sentiment_data.empty:\n",
    "        print(\"No data available for this sentiment.\")\n",
    "        return\n",
    "    \n",
    "    # Vectorize the text data\n",
    "    vectorizer = CountVectorizer(max_df=0.9, min_df=6, stop_words='english')\n",
    "    dtm = vectorizer.fit_transform(sentiment_data)\n",
    "    \n",
    "    # Fit LDA model\n",
    "    lda = LatentDirichletAllocation(n_components=n_topics, random_state=42)\n",
    "    lda.fit(dtm)\n",
    "    \n",
    "    # Extract and print topics\n",
    "    for idx, topic in enumerate(lda.components_):\n",
    "        print(f\"Topic {idx}: {[vectorizer.get_feature_names_out()[i] for i in topic.argsort()[-max_features:]]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing themes for Posts data\n",
      "\n",
      "Analyzing topics for sentiment: neutral\n",
      "Topic 0: ['nyulangone', 'traumatic', 'symptoms', 'participants', 'research', 'survey', 'https', 'tbi', 'ptsd', 'study']\n",
      "Topic 1: ['niaid', 'university', 'study', 'bethesda', '18', 'md', 'usa', 'clinicaltrials', 'https', 'gov']\n",
      "Topic 2: ['experience', 'help', 've', 'patients', 'patient', 'study', 'trials', 'research', 'trial', 'clinical']\n",
      "Topic 3: ['site', 'study', 'phase', 'patient', 'new', 'trials', 'cancer', 'trial', 'clinical', 'treatment']\n",
      "Topic 4: ['mailto', 'com', 'contact', 'brain', 'research', 'information', 'clinical', 'placebo', 'study', 'org']\n",
      "\n",
      "Analyzing topics for sentiment: negative\n",
      "Topic 0: ['study', 'clinical', 'just', 'patient', 'work', 'trials', 'trial']\n",
      "Topic 1: ['patient', 'study', 'just', 'trial', 'work', 'trials', 'clinical']\n",
      "Topic 2: ['study', 'trials', 'just', 'trial', 'clinical', 'patient', 'work']\n",
      "Topic 3: ['trials', 'work', 'just', 'clinical', 'study', 'trial', 'patient']\n",
      "Topic 4: ['clinical', 'trial', 'patient', 'trials', 'work', 'just', 'study']\n",
      "\n",
      "Analyzing topics for sentiment: positive\n",
      "Topic 0: ['people', 'trial', 'clinical', 'trials']\n",
      "Topic 1: ['trial', 'trials', 'people', 'clinical']\n",
      "Topic 2: ['trial', 'people', 'clinical', 'trials']\n",
      "Topic 3: ['trials', 'people', 'trial', 'clinical']\n",
      "Topic 4: ['clinical', 'people', 'trials', 'trial']\n"
     ]
    }
   ],
   "source": [
    "#for Posts data \n",
    "processed_df['combined_text'] = processed_df['title'] + \" \" + processed_df['body_text']\n",
    "print(\"Analyzing themes for Posts data\")\n",
    "# Analyze topics for each sentiment\n",
    "for sentiment in processed_df['sentiment_label'].unique():\n",
    "    analyze_topics_for_sentiment(processed_df, sentiment, n_topics=5, max_features=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing themes for Comments data\n",
      "\n",
      "Analyzing topics for sentiment: positive\n",
      "Topic 0: ['trial', 'thank', 'trials', 'iqvia', 'small', 'new', 'good', 'thanks', 'research', 'clinical']\n",
      "Topic 1: ['know', 'protocol', 'cros', 'people', 'good', 'cra', 'new', 'love', 'advice', 'thank']\n",
      "Topic 2: ['work', 'life', 'job', 'industry', 'crc', 'years', 'cra', 'experience', 'clinical', 'research']\n",
      "Topic 3: ['live', 'help', 'little', 'visits', 'icon', 'edc', 'like', 'thank', 'site', 'cra']\n",
      "Topic 4: ['company', 'crc', 'people', 'good', 'just', 'sponsor', 'like', 'cro', 'job', 'work']\n",
      "\n",
      "Analyzing topics for sentiment: negative\n",
      "Topic 0: ['people', 'don', 'company', 'like', 'sponsor', 'just', 'new', 'medpace', 'cro', 'work']\n",
      "Topic 1: ['thing', 'like', 'patients', 'want', 'research', 'document', 'don', 'just', 'study', 'patient']\n",
      "Topic 2: ['don', 'people', 'cra', 'years', 'jobs', 'just', 'experience', 'clinical', 'research', 'job']\n",
      "Topic 3: ['trial', 'just', 'patients', 'better', 'icon', 'job', 'know', 'industry', 'pi', 'don']\n",
      "Topic 4: ['cro', 'study', 'cras', 'just', 'like', 'sponsor', 'don', 'time', 'site', 'cra']\n",
      "\n",
      "Analyzing topics for sentiment: neutral\n",
      "Topic 0: ['need', 'don', 'like', 'sites', 'just', 'patient', 'time', 'data', 'study', 'site']\n",
      "Topic 1: ['want', 'advice', 'need', 'just', 'job', 'new', 'medpace', 'work', 'clinical', 'research']\n",
      "Topic 2: ['company', 'role', 'experience', 'years', 'icon', 'job', 'sponsor', 'work', 'cro', 'cra']\n",
      "Topic 3: ['people', 'crc', 'data', 'level', 'cra', 'job', 'years', 'experience', 'clinical', 'research']\n",
      "Topic 4: ['consent', 'site', 'drug', 'medical', 'research', 'trials', 'pi', 'trial', 'clinical', 'study']\n"
     ]
    }
   ],
   "source": [
    "print(\"Analyzing themes for Comments data\")\n",
    "# Analyze topics for each sentiment for Comments data\n",
    "comments_df['combined_text'] = comments_df['post_title'] + \" \" + comments_df['comment_body']\n",
    "for sentiment in comments_df['sentiment_label'].unique():\n",
    "    analyze_topics_for_sentiment(comments_df, sentiment, n_topics=5, max_features=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Observations**\n",
    "- Neutral Sentiment Dominance: Both posts and comments with neutral sentiment provide factual, logistic-focused discussions, reflecting the nature of clinical research communities.\n",
    "- Repetition in Positive and Negative Sentiments: Positive and negative topics often use repetitive keywords, particularly in posts, which may indicate a lack of diversity in sentiment-specific discussions.\n",
    "- Professional Focus in Comments: Comments, across all sentiments, show a strong emphasis on career-related terms like \"cra,\" \"cro,\" and \"sponsor,\". This can mean that method of removing career-focused or irrelevant posts are not accurately. I might need to look into other method that is more dynamic and not relied on a set of words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify Most Common words or key phrases with TF-IDF\n",
    "This section uses TF-IDF (Term Frequency-Inverse Document Frequency) to identify the most significant words and key phrases in posts and comments. The method highlights terms that are frequent in specific documents but uncommon across the entire dataset, making them more relevant to the content. By applying TF-IDF, common words are extracted for the overall dataset as well as for positive, negative, and neutral sentiment categories. This approach helps uncover distinct linguistic patterns and key phrases associated with each sentiment, providing deeper insights into the language used in clinical trial discussions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def apply_tfidf(df, text_column, sentiment_column=None, sentiment_value=None, max_features=100, ngram_range=(1, 1)):\n",
    "\n",
    "    # Filter by sentiment if specified\n",
    "    if sentiment_column and sentiment_value:\n",
    "        filtered_df = df[df[sentiment_column] == sentiment_value]\n",
    "        print(filtered_df.shape)\n",
    "    else:\n",
    "        filtered_df = df\n",
    "    \n",
    "    # Combine all text data into a single string for TF-IDF\n",
    "    text_data = filtered_df[text_column].dropna().tolist()\n",
    "    \n",
    "    # Apply TF-IDF\n",
    "    vectorizer = TfidfVectorizer(max_features=max_features, ngram_range=ngram_range, stop_words='english')\n",
    "    tfidf_matrix = vectorizer.fit_transform(text_data)\n",
    "    \n",
    "    # Extract terms and scores\n",
    "    terms = vectorizer.get_feature_names_out()\n",
    "    scores = tfidf_matrix.sum(axis=0).A1  # Sum TF-IDF scores across all documents\n",
    "    tfidf_df = pd.DataFrame({'term': terms, 'score': scores}).sort_values(by='score', ascending=False)\n",
    "    \n",
    "    return tfidf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neutral', 'negative', 'positive'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df['sentiment_label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "General TF-IDF:\n",
      "             term      score\n",
      "2        clinical  40.524944\n",
      "8           study  27.140628\n",
      "7        research  22.865330\n",
      "5           https  17.831205\n",
      "0              18   8.636337\n",
      "4             gov   7.455405\n",
      "9             usa   7.129458\n",
      "3  clinicaltrials   6.563470\n",
      "6              md   3.381821\n",
      "1        bethesda   2.976502\n",
      "(13, 15)\n",
      "\n",
      "TF-IDF for Positive Sentiment:\n",
      "       term     score\n",
      "1  clinical  4.771542\n",
      "8    trials  4.090183\n",
      "7     trial  3.479967\n",
      "6      time  2.212342\n",
      "9      work  1.925192\n",
      "3    people  1.920281\n",
      "5      site  1.880980\n",
      "4  research  1.792152\n",
      "2      like  1.530756\n",
      "0      best  1.389975\n",
      "(12, 15)\n",
      "\n",
      "TF-IDF for Negative Sentiment:\n",
      "       term     score\n",
      "8     trial  3.573427\n",
      "4  patients  3.509911\n",
      "0  clinical  3.504557\n",
      "3   patient  3.326698\n",
      "6     study  2.402698\n",
      "2      just  1.679895\n",
      "9      work  1.464485\n",
      "5      said  1.094170\n",
      "1       day  0.976687\n",
      "7  subjects  0.610092\n",
      "(75, 15)\n",
      "\n",
      "TF-IDF for Neutral Sentiment:\n",
      "             term      score\n",
      "2        clinical  30.911476\n",
      "7           study  22.497718\n",
      "5           https  17.329446\n",
      "0              18   8.743366\n",
      "9             usa   6.969478\n",
      "4             gov   6.253754\n",
      "3  clinicaltrials   6.021184\n",
      "6              md   3.329930\n",
      "1        bethesda   2.930802\n",
      "8      university   1.175849\n"
     ]
    }
   ],
   "source": [
    "# find overall tfidf for posts data\n",
    "overall_tfidf_processed_df = apply_tfidf(processed_df, text_column='combined_text', max_features=10)\n",
    "print(\"General TF-IDF:\")\n",
    "print(overall_tfidf_processed_df)\n",
    "\n",
    "# Find the TF-IDF for each sentiment\n",
    "# \"positive\" sentiment posts\n",
    "post_tfidf_positive = apply_tfidf(processed_df, text_column='combined_text', sentiment_column='sentiment_label', sentiment_value='positive', max_features=10)\n",
    "print(\"\\nTF-IDF for Positive Sentiment:\")\n",
    "print(post_tfidf_positive)\n",
    "\n",
    "# \"negative\" sentiment posts\n",
    "post_tfidf_negative = apply_tfidf(processed_df, text_column='combined_text', sentiment_column='sentiment_label', sentiment_value='negative', max_features=10)\n",
    "print(\"\\nTF-IDF for Negative Sentiment:\")\n",
    "print(post_tfidf_negative)\n",
    "\n",
    "# neutral sentiment posts\n",
    "post_tfidf_neutral = apply_tfidf(processed_df, text_column='combined_text', sentiment_column='sentiment_label', sentiment_value='neutral', max_features=10)\n",
    "print(\"\\nTF-IDF for Neutral Sentiment:\")\n",
    "print(post_tfidf_neutral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "General TF-IDF:\n",
      "         term        score\n",
      "1         cra  1414.894306\n",
      "9        work  1228.955042\n",
      "7    research  1203.196994\n",
      "0    clinical  1157.952053\n",
      "5        just  1089.836702\n",
      "4         job  1085.264334\n",
      "6        like   982.789417\n",
      "2         cro   970.992987\n",
      "8        site   859.173779\n",
      "3  experience   829.856807\n",
      "(2436, 9)\n",
      "\n",
      "TF-IDF for Positive Sentiment:\n",
      "         term       score\n",
      "1         cra  318.910229\n",
      "7    research  287.190761\n",
      "8       thank  268.807890\n",
      "9        work  259.208195\n",
      "0    clinical  257.695147\n",
      "4        good  238.418979\n",
      "5         job  219.308570\n",
      "6        like  197.543760\n",
      "2         cro  194.594254\n",
      "3  experience  174.634921\n",
      "(3359, 9)\n",
      "\n",
      "TF-IDF for Negative Sentiment:\n",
      "       term       score\n",
      "5      just  403.965403\n",
      "9      work  391.446134\n",
      "1       cra  384.126386\n",
      "4       job  381.352030\n",
      "3       don  374.093040\n",
      "6      like  335.887736\n",
      "2       cro  289.411828\n",
      "7    people  285.759602\n",
      "8  research  280.845648\n",
      "0  clinical  256.371900\n",
      "(5775, 9)\n",
      "\n",
      "TF-IDF for Neutral Sentiment:\n",
      "         term       score\n",
      "1         cra  741.341622\n",
      "0    clinical  629.916439\n",
      "6    research  626.274537\n",
      "9        work  571.187786\n",
      "5        just  493.917243\n",
      "2         cro  493.798610\n",
      "4         job  482.911453\n",
      "7        site  460.165879\n",
      "8       study  444.824776\n",
      "3  experience  433.372446\n"
     ]
    }
   ],
   "source": [
    "# Most common words per sentiment for comments data \n",
    "# find overall tfidf for comments data\n",
    "overall_tfidf_comments_df = apply_tfidf(comments_df, text_column='combined_text', max_features=10)\n",
    "print(\"General TF-IDF:\")\n",
    "print(overall_tfidf_comments_df)\n",
    "\n",
    "# Find the TF-IDF for each sentiment\n",
    "# \"positive\" sentiment comments\n",
    "cmt_tfidf_positive = apply_tfidf(comments_df, text_column='combined_text', sentiment_column='sentiment_label', sentiment_value='positive', max_features=10)\n",
    "print(\"\\nTF-IDF for Positive Sentiment:\")\n",
    "print(cmt_tfidf_positive)\n",
    "\n",
    "# \"negative\" sentiment comments\n",
    "cmt_tfidf_negative = apply_tfidf(comments_df, text_column='combined_text', sentiment_column='sentiment_label', sentiment_value='negative', max_features=10)\n",
    "print(\"\\nTF-IDF for Negative Sentiment:\")\n",
    "print(cmt_tfidf_negative)\n",
    "\n",
    "# neutral sentiment comments\n",
    "cmt_tfidf_neutral = apply_tfidf(comments_df, text_column='combined_text', sentiment_column='sentiment_label', sentiment_value='neutral', max_features=10)\n",
    "print(\"\\nTF-IDF for Neutral Sentiment:\")\n",
    "print(cmt_tfidf_neutral)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**: \n",
    "- Dominant terms like \"clinical,\" \"study,\" and \"research\" in posts indicate a strong emphasis on clinical trials and research participation. The data also reveals several posts discussing the latest clinical trials actively recruiting participants. \n",
    "- In both posts and comments, positive sentiment emphasizes terms like \"clinical,\" \"trials,\" \"research,\" and \"thank\" suggesting some sort of optimisim sentiment towards trials and research \n",
    "- Negative comments frequently use terms like \"job,\" \"work,\" \"don,\" and \"cra,\". As addressed above, this mean that my method is not 100% full proof of removing career-oriented posts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify Interest Level\n",
    "This section addresses the question: \"How can we identify users who are most interested in clinical trials based on their activity, sentiment, and intent?\" To determine interest levels, a scoring system was created that combines multiple metrics, each with assigned weights, to rank users based on their likelihood of engaging in clinical trials.\n",
    "\n",
    "Metrics Used in Scoring:\n",
    "\n",
    "1. User Activity (30% weight):\n",
    "    - Users who post or comment more frequently receive higher scores.\n",
    "    - Posting/commenting activity is normalized, and both types are combined into a total activity score.\n",
    "\n",
    "2. Sentiment-Based Weighting (20% weight):\n",
    "    - Positive posts/comments add to the score.\n",
    "    - Negative posts/comments detract from the score.\n",
    "    - Neutral activity contributes moderately.\n",
    "\n",
    "3. Intent Detection (50% weight):\n",
    "    - Posts with strong intent phrases like \"want to join,\" \"looking for trials,\" or \"how to participate\" are scored highest.\n",
    "    - Intent detection applies only to posts due to resource constraints and its strong impact on relevance.\n",
    "\n",
    "A scoring function combines the three metrics into a single interest score using the formula:\n",
    "\n",
    "$$\\text{Interest Score}= w_1​\\times \\text{Activity Score} +w_|2​\\times \\text{Sentiment Score} +w_3​\\times \\text{Intent Score}$$\n",
    "\n",
    "Weights: $w1=0.3$, $w2=0.2$ , $w3=0.5$\n",
    "\n",
    "**Notes**: \n",
    "- Activity Score: Calculated using normalized posting/commenting frequency.\n",
    "- Sentiment Score: Accounts for the ratio of positive to negative posts/comments.\n",
    "- Intent Score: determined by averaging the mapped values of intent levels for each user, where \"strong\" intent is scored as 1.0, \"weak\" intent as 0.5, and \"no interest\" as 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'strong'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "client= OpenAI()\n",
    "# Define the structured output with Pydantic\n",
    "class InterestIntent(BaseModel):\n",
    "    intent: str  # Values: 'strong', 'weak', 'no interest'\n",
    "\n",
    "# Function to parse response\n",
    "def classify_intent(text: str):\n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o-mini\",  # Adjust for your GPT version\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Classify the user's intent into strong, weak, or no interest based on the text\"},\n",
    "            {\"role\": \"user\", \"content\": text},\n",
    "        ],\n",
    "        response_format=InterestIntent,  # Use the Pydantic model\n",
    "    )\n",
    "    return completion.choices[0].message.parsed.intent\n",
    "\n",
    "# Example Input\n",
    "post_text = \"I would love to join this clinical trial if it meets my conditions. Can you tell me more about the process?\"\n",
    "\n",
    "# Classify the intent\n",
    "result = classify_intent(post_text)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df['intent'] = processed_df['combined_text'].apply(classify_intent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#calculate interest level \n",
    "# w1: activity weight, w2: sentiment weight, w3: intent weight\n",
    "w1, w2, w3 = (0.3, 0.2, 0.5) \n",
    "    \n",
    "# Aggregate posts data\n",
    "posts_agg = processed_df.groupby('author').agg(\n",
    "        post_count=('author', 'size'),\n",
    "        positive_posts=('sentiment_label', lambda x: (x == 'positive').sum()),\n",
    "        neutral_posts=('sentiment_label', lambda x: (x == 'neutral').sum()),\n",
    "        negative_posts=('sentiment_label', lambda x: (x == 'negative').sum()),\n",
    "        avg_intent_score=('intent', lambda x: x.map({'strong': 1.0, 'weak': 0.5, 'no interest': 0.0}).mean())\n",
    "    ).reset_index()\n",
    "\n",
    "# Aggregate comments data\n",
    "comments_agg = comments_df.groupby('comment_author').agg(\n",
    "    comment_count=('comment_author', 'size'),\n",
    "    positive_comments=('sentiment_label', lambda x: (x == 'positive').sum()),\n",
    "    neutral_comments=('sentiment_label', lambda x: (x == 'neutral').sum()),\n",
    "    negative_comments=('sentiment_label', lambda x: (x == 'negative').sum())\n",
    ").reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_author</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>positive_comments</th>\n",
       "      <th>neutral_comments</th>\n",
       "      <th>negative_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000Jelly</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0123_456_789</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100percentmillenial</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>109genp_fully</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10brat</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        comment_author  comment_count  positive_comments  neutral_comments  \\\n",
       "0             000Jelly              1                  0                 1   \n",
       "1         0123_456_789              1                  0                 1   \n",
       "2  100percentmillenial              1                  0                 1   \n",
       "3        109genp_fully              2                  0                 0   \n",
       "4               10brat              1                  0                 0   \n",
       "\n",
       "   negative_comments  \n",
       "0                  0  \n",
       "1                  0  \n",
       "2                  0  \n",
       "3                  2  \n",
       "4                  1  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_agg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>post_count</th>\n",
       "      <th>positive_posts</th>\n",
       "      <th>neutral_posts</th>\n",
       "      <th>negative_posts</th>\n",
       "      <th>avg_intent_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AcanthisittaSea6459</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accomplished_Cat5475</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AnonymousStrawb</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Appropriate-Tear4783</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CNDLab</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 author  post_count  positive_posts  neutral_posts  \\\n",
       "0   AcanthisittaSea6459           1               0              1   \n",
       "1  Accomplished_Cat5475           1               0              1   \n",
       "2       AnonymousStrawb           1               0              1   \n",
       "3  Appropriate-Tear4783           1               0              1   \n",
       "4                CNDLab           2               0              2   \n",
       "\n",
       "   negative_posts  avg_intent_score  \n",
       "0               0              0.50  \n",
       "1               0              1.00  \n",
       "2               0              1.00  \n",
       "3               0              1.00  \n",
       "4               0              0.75  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_agg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>post_count</th>\n",
       "      <th>positive_posts</th>\n",
       "      <th>neutral_posts</th>\n",
       "      <th>negative_posts</th>\n",
       "      <th>avg_intent_score</th>\n",
       "      <th>comment_author</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>positive_comments</th>\n",
       "      <th>neutral_comments</th>\n",
       "      <th>negative_comments</th>\n",
       "      <th>total_activity</th>\n",
       "      <th>activity_score</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>interest_score</th>\n",
       "      <th>interest_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N/A</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N/A</td>\n",
       "      <td>319.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.053125</td>\n",
       "      <td>0.789375</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JamieCFlores</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>JamieCFlores</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.00627</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.701881</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OtherwiseSlip6516</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lolita2805</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mwrig2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              author  post_count  positive_posts  neutral_posts  \\\n",
       "0                N/A         1.0             1.0            0.0   \n",
       "1       JamieCFlores         1.0             1.0            0.0   \n",
       "2  OtherwiseSlip6516         1.0             1.0            0.0   \n",
       "3         lolita2805         1.0             1.0            0.0   \n",
       "4             mwrig2         1.0             1.0            0.0   \n",
       "\n",
       "   negative_posts  avg_intent_score comment_author  comment_count  \\\n",
       "0             0.0               1.0            N/A          319.0   \n",
       "1             0.0               1.0   JamieCFlores            2.0   \n",
       "2             0.0               1.0              0            0.0   \n",
       "3             0.0               1.0              0            0.0   \n",
       "4             0.0               1.0              0            0.0   \n",
       "\n",
       "   positive_comments  neutral_comments  negative_comments  total_activity  \\\n",
       "0               28.0             245.0               46.0           320.0   \n",
       "1                2.0               0.0                0.0             3.0   \n",
       "2                0.0               0.0                0.0             1.0   \n",
       "3                0.0               0.0                0.0             1.0   \n",
       "4                0.0               0.0                0.0             1.0   \n",
       "\n",
       "   activity_score  sentiment_score  interest_score interest_level  \n",
       "0         1.00000        -0.053125        0.789375           high  \n",
       "1         0.00627         1.000000        0.701881           high  \n",
       "2         0.00000         1.000000        0.700000         medium  \n",
       "3         0.00000         1.000000        0.700000         medium  \n",
       "4         0.00000         1.000000        0.700000         medium  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# user stats: \n",
    "user_stats = pd.merge(posts_agg, comments_agg, left_on='author',right_on='comment_author', how='outer').fillna(0)\n",
    "\n",
    "# Total activity: sum of posts and comments\n",
    "user_stats['total_activity'] = user_stats['post_count'] + user_stats['comment_count']\n",
    "\n",
    "# Normalize activity score\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "user_stats['activity_score'] = scaler.fit_transform(user_stats[['total_activity']])\n",
    "\n",
    "total_positive = user_stats['positive_posts'] + user_stats['positive_comments']\n",
    "total_negative = user_stats['negative_posts'] + user_stats['negative_comments']\n",
    "total_count = user_stats['total_activity']\n",
    "user_stats['sentiment_score'] = ((total_positive - total_negative) / total_count).fillna(0)\n",
    "\n",
    "# calculate intent score\n",
    "user_stats['interest_score'] = (\n",
    "        w1 * user_stats['activity_score'] +\n",
    "        w2 * user_stats['sentiment_score'] +\n",
    "        w3 * user_stats['avg_intent_score']\n",
    "    )\n",
    "# determine the interest level\n",
    "user_stats['interest_level'] = user_stats['interest_score'].apply(lambda x: 'high' if x > 0.7 else 'low' if x < 0.3 else 'medium')\n",
    "user_stats= user_stats.sort_values(by='interest_score', ascending=False).reset_index(drop=True)\n",
    "user_stats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Personalized Message based on Users \n",
    "We first get users who have a high interest level. The code section below will demonstrate how can you get personalized message given all the users' prior posts and comments to the subreddit \n",
    "\n",
    "1. **Aggregate User Content:**  \n",
    "   - For a given user name `user`, all text from the `combined_text` column in the `user_content` DataFrame is combined into a single string.  \n",
    "   - This aggregated text represents the user's posts and comments and the posts' content corresponding to that comment\n",
    "\n",
    "2. **Extract Demographic Data:**  \n",
    "   - The aggregated text is processed using GPT and a predefined prompt to extract key user details:\n",
    "     - Gender, age, research topics, health conditions, location, etc.\n",
    "   - The extracted data is returned in a structured JSON format.\n",
    "\n",
    "3. **Generate Personalized Message:**  \n",
    "   - The extracted data is used to create a tailored message emphasizing the user’s suitability for a clinical trial.\n",
    "   - Fallback values are applied to ensure the message remains complete if certain details are unavailable.\n",
    "\n",
    "**Notes:** It is very normal to have users who don't list any of their user information at all "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_tmp = comments_df.rename(columns={'combined_text': 'comment_combined_text'})\n",
    "# first join comments and posts data\n",
    "comments_with_post_info = pd.merge(\n",
    "    processed_df[['combined_text']].reset_index(), \n",
    "    comments_tmp, \n",
    "    left_on='index', \n",
    "    right_on='post_id', \n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "comments_with_post_info['comments_n_post_text'] = comments_with_post_info['combined_text'] + \" \" + comments_with_post_info['comment_combined_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape:  (192, 3)\n"
     ]
    }
   ],
   "source": [
    "# users with high interest\n",
    "interest_user = user_stats[user_stats['interest_level'].isin(['high', 'medium'])]\n",
    "\n",
    "# filter only users with interest\n",
    "\n",
    "comments_tmp = comments_df.rename(columns={'combined_text': 'comment_combined_text'})\n",
    "comments_tmp = comments_tmp[comments_tmp['comment_author'].isin(interest_user['author'])]\n",
    "processed_df_tmp = processed_df[processed_df['author'].isin(interest_user['author'])]\n",
    "\n",
    "# first join comments and posts data\n",
    "comments_with_post_info = pd.merge(\n",
    "    processed_df_tmp[['combined_text']].reset_index(), \n",
    "    comments_tmp, \n",
    "    left_on='index', \n",
    "    right_on='post_id', \n",
    "    how='inner'\n",
    ")\n",
    "# join the comments and posts info together to create context for the comments\n",
    "comments_with_post_info['comments_n_post_text'] = comments_with_post_info['combined_text'] + \" \" + comments_with_post_info['comment_combined_text']\n",
    "\n",
    "# Filter posts and comments for the users in the list\n",
    "posts = processed_df_tmp[['author', 'combined_text']].copy()\n",
    "comments = comments_with_post_info[['comment_author', 'comments_n_post_text']].copy()\n",
    "\n",
    "# Add the content_type column to distinguish the source\n",
    "posts['content_type'] = 'post'\n",
    "comments['content_type'] = 'comments'\n",
    "\n",
    "\n",
    "# Rename columns for consistency before merging\n",
    "posts.rename(columns={'author': 'user'}, inplace=True)\n",
    "comments.rename(columns={'comment_author': 'user', 'comments_n_post_text':'combined_text'}, inplace=True)\n",
    "\n",
    "# Merge the two DataFrames\n",
    "user_content = pd.concat([posts, comments], ignore_index=True).reset_index(drop=True)\n",
    "\n",
    "# Optional: Sort by user for easier inspection\n",
    "print(\"Data shape: \", user_content.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique user who are medium/high interest in joining a study:  59\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of unique user who are medium/high interest in joining a study: \",user_content['user'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All users in interest_user are in user_content: True\n"
     ]
    }
   ],
   "source": [
    "all_users_present=interest_user['author'].isin(user_content['user']).all()\n",
    "\n",
    "# check if all the  user in interest_user is in user_content\n",
    "print(\"All users in interest_user are in user_content:\", all_users_present)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "client= OpenAI()\n",
    "\n",
    "prompt = \"\"\"\n",
    "You are tasked with extracting specific user information from a given set of posts and comments. Analyze the provided text and extract the following details:\n",
    "\n",
    "1. **Gender:** Extract the user's gender if explicitly mentioned or can be inferred from pronouns, phrases, or statements in the text (e.g., \"male\", \"female\", \"non-binary\"). If not mentioned, return \"Null\".\n",
    "\n",
    "2. **Age:** Extract the user's exact age or age range if explicitly mentioned in the text (e.g., \"25 years old\", \"in my thirties\"). Turn the text into integer, for example \"25 years old\" to 25. If not mentioned, return \"Null\".\n",
    "\n",
    "3. **Mentioned Research Topics:** Identify any **specific fields or areas of research** that the user explicitly discusses or shows interest in through their posts or comments. These may include fields such as \"neuroscience,\" \"cancer,\" \"cardiovascular health,\" or \"dermatology.\"  \n",
    "   - **Do not include generic terms** like \"clinical trials,\" \"research,\" \"studies,\" or \"research participation.\"\n",
    "   - **Only extract meaningful research fields.** If none are explicitly mentioned, return \"Null.\"\n",
    "\n",
    "4. **Language:** Determine the user's language preference if explicitly mentioned in the text (e.g., \"I prefer communicating in Spanish\"). If not mentioned, return \"Null\".\n",
    "\n",
    "5. **Health Condition:** Extract any specific health conditions or diseases mentioned by the user (e.g., \"diabetes\", \"hypertension\"). If none are mentioned, return \"Null\".\n",
    "\n",
    "6. **Medication:** Extract any medications mentioned by the user (e.g., \"metformin\", \"insulin\"). If none are mentioned, return \"Null\".\n",
    "\n",
    "7. **Treatment:** Identify any treatments the user mentions undergoing or considering (e.g., \"radiation therapy\", \"physical therapy\"). If not mentioned, return \"Null\".\n",
    "\n",
    "8. **Location:** Extract any location details mentioned by the user (e.g., \"Boston, MA\", \"United States\"). If not mentioned, return \"Null\".\n",
    "\n",
    "---\n",
    "\n",
    "**Important Notes:**\n",
    "- **Do not include generic terms** like \"clinical trials,\" \"research,\" \"studies,\" or \"research participation\" in the `mentioned_research_topic` field.\n",
    "- Only extract information explicitly stated in the text. Do not infer or assume any details not directly mentioned.\n",
    "- Return the result in the following structured JSON format:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"gender\": \"Extracted or Null\",\n",
    "  \"age\": \"Extracted or Null\",\n",
    "  \"mentioned_research_topic\": \"Extracted topics or Null\",\n",
    "  \"language\": \"Extracted or Null\",\n",
    "  \"health_condition\": \"Extracted or Null\",\n",
    "  \"medication\": \"Extracted or Null\",\n",
    "  \"treatment\": \"Extracted or Null\",\n",
    "  \"location\": \"Extracted or Null\"\n",
    "}\n",
    "\"\"\"\n",
    "# Function to parse response\n",
    "def extract_user_info(text: str, prompt: str):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",  # Adjust for your GPT version\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": prompt},\n",
    "            {\"role\": \"user\", \"content\": text},\n",
    "        ]\n",
    "    )\n",
    "    return completion.choices[0].message.content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'```json\\n{\\n  \"gender\": \"male\",\\n  \"age\": 35,\\n  \"mentioned_research_topic\": \"Null\",\\n  \"language\": \"English\",\\n  \"health_condition\": \"Type 2 Diabetes\",\\n  \"medication\": \"metformin\",\\n  \"treatment\": \"Null\",\\n  \"location\": \"New York\"\\n}\\n```'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example Input\n",
    "post_text = \"I am a 35-year-old male living in New York. I've been diagnosed with Type 2 Diabetes and currently take metformin. I’m interested in participating in clinical trials. I speak English.\"\n",
    "\n",
    "# Classify the intent\n",
    "result = extract_user_info(post_text, prompt)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi future participant,\n",
      "    \n",
      "    Thank you for your interest in advancing medical research! Based on your profile, we believe you might be an excellent candidate for a clinical trial focusing on medical research.\n",
      "    \n",
      "    This trial is designed for individuals with Type 2 Diabetes in New York. Your experience with metformin could provide invaluable insights.\n",
      "    \n",
      "    If you’re interested in participating, please visit [trial link] or contact us at [contact info] to learn more.\n",
      "    \n",
      "    Your contribution could help shape the future of medical research care and treatment.\n",
      "    \n",
      "    Best regards,\n",
      "    Clinical Trial Team\n"
     ]
    }
   ],
   "source": [
    "def create_personalized_message(result):\n",
    "    cleaned_result = result.strip().strip(\"```\").replace(\"json\", \"\").strip()\n",
    "    user_info = json.loads(cleaned_result)\n",
    "\n",
    "    # Process and extract information\n",
    "    gender = user_info.get(\"gender\", \"participant\")\n",
    "    gender = \"participant\" if gender == \"Null\" else gender\n",
    "\n",
    "    age = user_info.get(\"age\", \"your age group\")\n",
    "    age = \"your age group\" if age == \"Null\" else age\n",
    "\n",
    "    location = user_info.get(\"location\", \"your area\")\n",
    "    location = \"your area\" if location == \"Null\" else location\n",
    "\n",
    "    research_topic = user_info.get(\"mentioned_research_topic\", \"medical research\")\n",
    "    research_topic = \"medical research\" if research_topic == \"Null\" else research_topic\n",
    "\n",
    "    health_condition = user_info.get(\"health_condition\", \"your health\")\n",
    "    health_condition = \"your health condition\" if health_condition == \"Null\" else health_condition\n",
    "\n",
    "    medication = user_info.get(\"medication\", \"your current treatment\")\n",
    "    medication = \"your current treatment\" if medication == \"Null\" else medication\n",
    "\n",
    "    # Generate the personalized message\n",
    "    message = f\"\"\"\n",
    "    Hi future participant,\n",
    "    \n",
    "    Thank you for your interest in advancing medical research! Based on your profile, we believe you might be an excellent candidate for a clinical trial focusing on {research_topic}.\n",
    "    \n",
    "    This trial is designed for individuals with {health_condition} in {location}. Your experience with {medication} could provide invaluable insights.\n",
    "    \n",
    "    If you’re interested in participating, please visit [trial link] or contact us at [contact info] to learn more.\n",
    "    \n",
    "    Your contribution could help shape the future of {research_topic} care and treatment.\n",
    "    \n",
    "    Best regards,\n",
    "    Clinical Trial Team\n",
    "    \"\"\"\n",
    "    return message.strip()\n",
    "\n",
    "# Generate the personalized message\n",
    "personalized_message = create_personalized_message(result)\n",
    "print(personalized_message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(192, 3)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display users with high interest\n",
    "user_content.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clinical Trials for all Good evening Everyone,\n",
      "\n",
      "I just recently joined the sub-reddit, and I've been more of a casual browser on Reddit than an active user. But I reach out to you today, because as a member of this channel I'm sure we all share at least one common interest, and that's Clinical Trials. \n",
      "\n",
      "I myself am based out of Tokyo, and am a rookie in the field, but I am really motivated and impassioned about the topic!\n",
      "\n",
      "My objective is simple. With people being a little more in tune with clinical trial information (COVID pushing it into the public eye and radar a lot more), I feel like this is an ideal time to make some information accessible. I'm not talking about fantastic 3 hour seminars on YouTube that industry professionals would enjoy. I'm thinking a little more PR, layman, pop-science access to the massive mountain of information and complexity that is clinical trials.  It be cool to have non-corporate・non-PR industry perspectives, or fire side chat, or dialogue, or breakdowns for people to share. \n",
      "\n",
      "Part of it has been planning and thinking about what people would like, or what may be easier to create, who to best reach out to, but it's been wasting valuable time. The best thing is to just start something and get the ball rolling. Hence this post to you guys (and gals) in the hopes of starting a thread of ideas, or topics, opinions, or even dissent about this idea. \n",
      "\n",
      "&#x200B;\n",
      "\n",
      "Thanks for reading through, and leave a comment or suggestion! (Even if it's just a \"Cool ,best of luck with that\").  :) Clinical Trials for all Good evening Everyone,\n",
      "\n",
      "I just recently joined the sub-reddit, and I've been more of a casual browser on Reddit than an active user. But I reach out to you today, because as a member of this channel I'm sure we all share at least one common interest, and that's Clinical Trials. \n",
      "\n",
      "I myself am based out of Tokyo, and am a rookie in the field, but I am really motivated and impassioned about the topic!\n",
      "\n",
      "My objective is simple. With people being a little more in tune with clinical trial information (COVID pushing it into the public eye and radar a lot more), I feel like this is an ideal time to make some information accessible. I'm not talking about fantastic 3 hour seminars on YouTube that industry professionals would enjoy. I'm thinking a little more PR, layman, pop-science access to the massive mountain of information and complexity that is clinical trials.  It be cool to have non-corporate・non-PR industry perspectives, or fire side chat, or dialogue, or breakdowns for people to share. \n",
      "\n",
      "Part of it has been planning and thinking about what people would like, or what may be easier to create, who to best reach out to, but it's been wasting valuable time. The best thing is to just start something and get the ball rolling. Hence this post to you guys (and gals) in the hopes of starting a thread of ideas, or topics, opinions, or even dissent about this idea. \n",
      "\n",
      "&#x200B;\n",
      "\n",
      "Thanks for reading through, and leave a comment or suggestion! (Even if it's just a \"Cool ,best of luck with that\").  :) Clinical Trials for all Thanks. Looks like a good piece to have a discussion about. I’ll read it later tonight! Clinical Trials for all Good evening Everyone,\n",
      "\n",
      "I just recently joined the sub-reddit, and I've been more of a casual browser on Reddit than an active user. But I reach out to you today, because as a member of this channel I'm sure we all share at least one common interest, and that's Clinical Trials. \n",
      "\n",
      "I myself am based out of Tokyo, and am a rookie in the field, but I am really motivated and impassioned about the topic!\n",
      "\n",
      "My objective is simple. With people being a little more in tune with clinical trial information (COVID pushing it into the public eye and radar a lot more), I feel like this is an ideal time to make some information accessible. I'm not talking about fantastic 3 hour seminars on YouTube that industry professionals would enjoy. I'm thinking a little more PR, layman, pop-science access to the massive mountain of information and complexity that is clinical trials.  It be cool to have non-corporate・non-PR industry perspectives, or fire side chat, or dialogue, or breakdowns for people to share. \n",
      "\n",
      "Part of it has been planning and thinking about what people would like, or what may be easier to create, who to best reach out to, but it's been wasting valuable time. The best thing is to just start something and get the ball rolling. Hence this post to you guys (and gals) in the hopes of starting a thread of ideas, or topics, opinions, or even dissent about this idea. \n",
      "\n",
      "&#x200B;\n",
      "\n",
      "Thanks for reading through, and leave a comment or suggestion! (Even if it's just a \"Cool ,best of luck with that\").  :) Clinical Trials for all Hey Chiraag! Greta content and power point slides to guide the discussion. I think this video has a great pacing and good simplified information. Definitely along the lines of the original post theme.  What a coincidence that your upload timing was so close? Haha\n",
      "\n",
      "My only take on it to make it even easier to digest and easier to produce would be to break it down into even smaller digestible chunks. 15 mins as an overview can be a lot to process for a newbie. What if we could abridge it, and then have more bite sized clips with specifics on the channel if they want to dig further? \n",
      "\n",
      "Awesome contribution.\n"
     ]
    }
   ],
   "source": [
    "# Example: Aggregating and processing user data\n",
    "user_name = \"JamieCFlores\" # high level of interest\n",
    "user_context = \" \".join(user_content[user_content['user'] == user_name]['combined_text'].transform(str))\n",
    "print(user_context)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"gender\": \"Null\",\n",
      "  \"age\": \"Null\",\n",
      "  \"mentioned_research_topic\": \"Null\",\n",
      "  \"language\": \"Null\",\n",
      "  \"health_condition\": \"Null\",\n",
      "  \"medication\": \"Null\",\n",
      "  \"treatment\": \"Null\",\n",
      "  \"location\": \"Tokyo\"\n",
      "}\n",
      "```\n",
      "Hi future participant,\n",
      "    \n",
      "    Thank you for your interest in advancing medical research! Based on your profile, we believe you might be an excellent candidate for a clinical trial focusing on medical research.\n",
      "    \n",
      "    This trial is designed for individuals with your health condition in Tokyo. Your experience with your current treatment could provide invaluable insights.\n",
      "    \n",
      "    If you’re interested in participating, please visit [trial link] or contact us at [contact info] to learn more.\n",
      "    \n",
      "    Your contribution could help shape the future of medical research care and treatment.\n",
      "    \n",
      "    Best regards,\n",
      "    Clinical Trial Team\n"
     ]
    }
   ],
   "source": [
    "# Extract demographic details\n",
    "user_info = extract_user_info(user_context, prompt)\n",
    "print(user_info)\n",
    "\n",
    "# Generate personalized message\n",
    "personalized_message = create_personalized_message(user_info)\n",
    "print(personalized_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**\n",
    "\n",
    "- This solution for personalized messages will allow for robust structured output to find user information. However, it still faces some challenges with hallucinations and inefficiencies due to repeated information from aggregating all posts and associated comments, as the context for multiple comments often redundantly includes the same post text."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "blurry_clear_imagedetection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
